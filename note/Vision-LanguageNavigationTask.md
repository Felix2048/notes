# Vision-Language Navigation Task

## Problem Setup

## Dataset

Room-to-Room (R2R)[arxiv](https://arxiv.org/abs/1711.07280)

## Leaderboard

- Vision-Language Navigation with Self-Supervised Auxiliary Reasoning Tasks [[arxiv](https://arxiv.org/abs/1911.07883)][2019.11]
- Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout [[arxiv](https://arxiv.org/abs/1904.04195)][[code](https://github.com/airsplay/R2R-EnvDrop)][2019.04]
- Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation [[arxiv](http://arxiv.org/abs/1811.10092)][2018.11]
- Self-Monitoring Navigation Agent via Auxiliary Progress Estimation [[arxiv](https://arxiv.org/abs/1901.03035)][[code](https://github.com/chihyaoma/selfmonitoring-agent)][2019.01]
- Speaker-Follower Models for Vision-and-Language Navigation [[arxiv](https://arxiv.org/abs/1806.02724)][[code](https://github.com/ronghanghu/speaker_follower)][2018.06]
